{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spooky Authors Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to identify Spooky Authors for Kaggle Challenge\n",
    "## https://www.kaggle.com/c/spooky-author-identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_colwidth',10000)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\t\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import preprocessing\n",
    "from keras.models import Sequential\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data from \"train.csv\" file at: https://www.kaggle.com/c/spooky-author-identification/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training data\n",
      "Finished reading training data\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19579 entries, 0 to 19578\n",
      "Data columns (total 3 columns):\n",
      "id        19579 non-null object\n",
      "text      19579 non-null object\n",
      "author    19579 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 459.0+ KB\n"
     ]
    }
   ],
   "source": [
    "print('Reading training data')\n",
    "dataframe_train = pd.read_csv('train.csv').fillna(0)\n",
    "print('Finished reading training data')\n",
    "dataframe_train.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling might be a mere mistake.</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from which, as he capered down the hill, cutting all manner of fantastic steps, he took snuff incessantly with an air of the greatest possible self satisfaction.</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor Terrace on the sixteen fertile counties spread beneath, speckled by happy cottages and wealthier towns, all looked as in former years, heart cheering and fair.</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Superintendent abandoned his attempts; but a perplexed look occasionally steals over his countenance as he sits thinking at his desk.</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>id22965</td>\n",
       "      <td>A youth passed in solitude, my best years spent under your gentle and feminine fosterage, has so refined the groundwork of my character that I cannot overcome an intense distaste to the usual brutality exercised on board ship: I have never believed it to be necessary, and when I heard of a mariner equally noted for his kindliness of heart and the respect and obedience paid to him by his crew, I felt myself peculiarly fortunate in being able to secure his services.</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>id09674</td>\n",
       "      <td>The astronomer, perhaps, at this point, took refuge in the suggestion of non luminosity; and here analogy was suddenly let fall.</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>id13515</td>\n",
       "      <td>The surcingle hung in ribands from my body.</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>id19322</td>\n",
       "      <td>I knew that you could not say to yourself 'stereotomy' without being brought to think of atomies, and thus of the theories of Epicurus; and since, when we discussed this subject not very long ago, I mentioned to you how singularly, yet with how little notice, the vague guesses of that noble Greek had met with confirmation in the late nebular cosmogony, I felt that you could not avoid casting your eyes upward to the great nebula in Orion, and I certainly expected that you would do so.</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>id00912</td>\n",
       "      <td>I confess that neither the structure of languages, nor the code of governments, nor the politics of various states possessed attractions for me.</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  \\\n",
       "0  id26305   \n",
       "1  id17569   \n",
       "2  id11008   \n",
       "3  id27763   \n",
       "4  id12958   \n",
       "5  id22965   \n",
       "6  id09674   \n",
       "7  id13515   \n",
       "8  id19322   \n",
       "9  id00912   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       text  \\\n",
       "0                                                                                                                                                                                                                                                                   This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                   It never once occurred to me that the fumbling might be a mere mistake.   \n",
       "2                                                                                                                                                                                                                                                                                                  In his left hand was a gold snuff box, from which, as he capered down the hill, cutting all manner of fantastic steps, he took snuff incessantly with an air of the greatest possible self satisfaction.   \n",
       "3                                                                                                                                                                                                                                                                                            How lovely is spring As we looked from Windsor Terrace on the sixteen fertile counties spread beneath, speckled by happy cottages and wealthier towns, all looked as in former years, heart cheering and fair.   \n",
       "4                                                                                                                                                                                                                                                                                                                            Finding nothing else, not even gold, the Superintendent abandoned his attempts; but a perplexed look occasionally steals over his countenance as he sits thinking at his desk.   \n",
       "5                      A youth passed in solitude, my best years spent under your gentle and feminine fosterage, has so refined the groundwork of my character that I cannot overcome an intense distaste to the usual brutality exercised on board ship: I have never believed it to be necessary, and when I heard of a mariner equally noted for his kindliness of heart and the respect and obedience paid to him by his crew, I felt myself peculiarly fortunate in being able to secure his services.   \n",
       "6                                                                                                                                                                                                                                                                                                                                                                          The astronomer, perhaps, at this point, took refuge in the suggestion of non luminosity; and here analogy was suddenly let fall.   \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                                                               The surcingle hung in ribands from my body.   \n",
       "8  I knew that you could not say to yourself 'stereotomy' without being brought to think of atomies, and thus of the theories of Epicurus; and since, when we discussed this subject not very long ago, I mentioned to you how singularly, yet with how little notice, the vague guesses of that noble Greek had met with confirmation in the late nebular cosmogony, I felt that you could not avoid casting your eyes upward to the great nebula in Orion, and I certainly expected that you would do so.   \n",
       "9                                                                                                                                                                                                                                                                                                                                                          I confess that neither the structure of languages, nor the code of governments, nor the politics of various states possessed attractions for me.   \n",
       "\n",
       "  author  \n",
       "0    EAP  \n",
       "1    HPL  \n",
       "2    EAP  \n",
       "3    MWS  \n",
       "4    HPL  \n",
       "5    MWS  \n",
       "6    EAP  \n",
       "7    EAP  \n",
       "8    EAP  \n",
       "9    MWS  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_train.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_words(corpus, n=None):\n",
    "    \"\"\"\n",
    "    List the top n words in a vocabulary according to occurrence in a text corpus.\n",
    "    \"\"\"\n",
    "    vec = CountVectorizer().fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in     vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 35585),\n",
       " ('of', 20955),\n",
       " ('and', 17956),\n",
       " ('to', 12843),\n",
       " ('in', 9458),\n",
       " ('was', 6647),\n",
       " ('that', 6447),\n",
       " ('my', 5418),\n",
       " ('it', 4915),\n",
       " ('he', 4433)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract most used words\n",
    "most_common_words = get_top_n_words(dataframe_train.text, n=10)\n",
    "most_common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 14993), ('of', 8972), ('and', 5735), ('to', 4765), ('in', 4124), ('that', 2333), ('it', 2332), ('was', 2224), ('my', 1788), ('with', 1696)]\n",
      "[('the', 10933), ('and', 6098), ('of', 5846), ('to', 3249), ('in', 2736), ('was', 2174), ('that', 2022), ('had', 1779), ('he', 1647), ('it', 1402)]\n",
      "[('the', 9659), ('of', 6137), ('and', 6123), ('to', 4829), ('my', 2659), ('in', 2598), ('was', 2249), ('that', 2092), ('her', 1657), ('his', 1646)]\n"
     ]
    }
   ],
   "source": [
    "# Extract most used words by each author\n",
    "EAP_words = get_top_n_words(dataframe_train.loc[dataframe_train['author'] == 'EAP'].text, n=10)\n",
    "HPL_words = get_top_n_words(dataframe_train.loc[dataframe_train['author'] == 'HPL'].text, n=10)\n",
    "MWS_words = get_top_n_words(dataframe_train.loc[dataframe_train['author'] == 'MWS'].text, n=10)\n",
    "\n",
    "print(EAP_words)\n",
    "print(HPL_words)\n",
    "print(MWS_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train sample and labels - vectorize either with \"Tfid\" or \"Count\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features is: 25068\n",
      "The vectorized array looks like:\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "X = dataframe_train.text.values\n",
    "y = dataframe_train.author\n",
    "\n",
    "# Build the vocabulary and vectorize the sentences\n",
    "#vectorizer = TfidfVectorizer()\n",
    "vectorizer = CountVectorizer(min_df=0)\n",
    "\n",
    "vector_X = vectorizer.fit_transform(X)\n",
    "features = len(vectorizer.get_feature_names())\n",
    "print(\"Number of features is:\", features)\n",
    "print(\"The vectorized array looks like:\")\n",
    "print(vector_X.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode and binarize labels for predictions\n",
    "# Encode\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "label_encoder.fit([\"EAP\", \"HPL\", \"MWS\"])\n",
    "encoded_y = label_encoder.transform(y)\n",
    "# Binarize\n",
    "label_binarizer = preprocessing.LabelBinarizer()\n",
    "label_binarizer.fit(encoded_y)\n",
    "binarized_y = label_binarizer.transform(encoded_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use NN to classify texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " - 11s - loss: 0.1855\n",
      "Epoch 2/2\n",
      " - 11s - loss: 0.0971\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a26b72278>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 2\n",
    "batch_size = 100\n",
    "\n",
    "\n",
    "# Define the Neural Network for predictions\n",
    "model = Sequential()\n",
    "model.add(Dense(9, input_dim=vector_X.shape[1], activation='relu'))\n",
    "model.add(Dense(6, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "# fit the model on the training set\n",
    "model.fit(vector_X, binarized_y, epochs=epochs, batch_size=batch_size, verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load test set from: https://www.kaggle.com/c/spooky-author-identification/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the output.csv file for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading test data\n",
      "Finished reading test data\n"
     ]
    }
   ],
   "source": [
    "print('Reading test data')\n",
    "dataframe_test = pd.read_csv('test.csv').fillna(0)\n",
    "print('Finished reading test data')\n",
    "\n",
    "\n",
    "X_submission = dataframe_test.text.values\n",
    "# encodes submissio test documents into a vector using the previous vectorizer\n",
    "vector_X_submission = vectorizer.transform(X_submission)\n",
    "# make predictions on submission test set\n",
    "predictions = model.predict(vector_X_submission)\n",
    "\n",
    "identifications = dataframe_test.id.values\n",
    "data = {'id': identifications, 'EAP': predictions[:,0], 'HPL': predictions[:,1], 'MWS': predictions[:,2]}\n",
    "dataframe_submission = pd.DataFrame(data=data)\n",
    "cols = ['id','EAP','HPL','MWS']\n",
    "dataframe_submission = dataframe_submission[cols]\n",
    "dataframe_submission.to_csv('output.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
